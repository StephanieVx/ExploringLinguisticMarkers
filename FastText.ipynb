{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.probability import FreqDist\n",
    "import lime.lime_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/uu_ics_ads/sverkleij/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "main_folder = 'Data/MD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "for file in Path(main_folder).iterdir():\n",
    "    with open(file, encoding = \"ISO-8859-1\") as file_open:\n",
    "        results[\"file_name\"].append(file.name)\n",
    "        results[\"text\"].append(file_open.read())\n",
    "        \n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "for file in Path('Data/NoMD').iterdir():\n",
    "    with open(file, encoding = \"ISO-8859-1\") as file_open:\n",
    "        results[\"file_name\"].append(file.name)\n",
    "        results[\"text\"].append(file_open.read())\n",
    "        \n",
    "df2 = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Disorder']='nomd'\n",
    "df['Disorder']='md'\n",
    "result1 = pd.concat([df, df2])\n",
    "del result1['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1['Text'] = result1['text']\n",
    "del result1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1['Text'] = result1['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmentald = pd.read_excel(r'MentalDisorders/LIWCresultstotal.xlsx')\n",
    "df.columns = ['Filename','Text']\n",
    "result = pd.merge(df, dfmentald, on='Filename', how = 'outer').fillna(0)\n",
    "del result['Filename']\n",
    "result1 = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1['Text']=result1['Text'].str.replace(r',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train Test Split Function\n",
    "def split_train_test(result, test_size=0.2, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result1[['Text']], \n",
    "                                                       result1['Disorder'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.merge(X_train, Y_train, on='index', how = 'outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Disorder', 'Text']\n",
    "\n",
    "yelp_reviews = result2[col]\n",
    "yelp_reviews['Disorder']=['__label__'+ s for s in yelp_reviews['Disorder']]\n",
    "yelp_reviews['Text']= yelp_reviews['Text'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "yelp_reviews.to_csv(r'MentalDisorders/yelp_reviews_updated.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulttest = pd.merge(X_test, Y_test, on='index', how = 'outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"Disorder\", \"Text\"]\n",
    "testset = resulttest[col]\n",
    "testset['Disorder']=['__label__'+ s for s in testset['Disorder']]\n",
    "testset['Text']= testset['Text'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "testset.to_csv(r'MentalDisorders/yelp_test.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(\"MentalDisorders/yelp_reviews_updated.txt\", epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "                                \n",
    "print_results(*model.test(\"MentalDisorders/yelp_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# predict the data\n",
    "testset[\"predicted\"] = testset[\"Text\"].apply(lambda x: model.predict(x)[0][0])\n",
    "\n",
    "# Create the confusion matrix\n",
    "confusion_matrix(testset[\"Disorder\"], testset[\"predicted\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "cohen_kappa_score(testset['Disorder'], testset['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(testset['Disorder'], testset['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fastText\n",
    "import re\n",
    "import webbrowser\n",
    "\n",
    "def strip_formatting(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(r\"([.!?,'/()])\", r\" \\1 \", string)\n",
    "    return string\n",
    "\n",
    "def tokenize_string(string):\n",
    "    return string.split()\n",
    "\n",
    "classifier = (model)\n",
    "\n",
    "explainer = lime.lime_text.LimeTextExplainer(\n",
    "    split_expression=tokenize_string,\n",
    "    bow=False,\n",
    "    class_names=[\"__label__nomd\", \"__label__md\"]\n",
    ")\n",
    "\n",
    "def fasttext_prediction_in_sklearn_format(classifier, texts):\n",
    "    res = []\n",
    "    labels, probabilities = classifier.predict(texts, 10)\n",
    "    for label, probs, text in zip(labels, probabilities, texts):\n",
    "        order = np.argsort(np.array(label))\n",
    "        res.append(probs[order])\n",
    "\n",
    "    return np.array(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = testset.iloc[4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the text of the review so it matches the training format\n",
    "preprocessed_review = strip_formatting(review)\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    preprocessed_review,\n",
    "    classifier_fn=lambda x: fasttext_prediction_in_sklearn_format(classifier, x),\n",
    "    top_labels=2,\n",
    "    num_features=10,\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(text=preprocessed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = (model.predict(review))\n",
    "print (results[1][0])\n",
    "print(testset.iloc[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
